{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python dictionary workflow\n",
    "\n",
    "Here we use the sentiment dictionary for the workflow, using Loughran-McDonald Master Dictionary w/ Sentiment Word Lists\n",
    "\n",
    "\n",
    "https://sraf.nd.edu/loughranmcdonald-master-dictionary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peterhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/peterhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# get the stop words here\n",
    "\n",
    "# download nltk package\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# add other stop words to fine tune the relevant model, use this for the other workflows here!!\n",
    "stopword=set(stopwords.words('english') + []) # add the other stop words here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(text, return_tokens = False):\n",
    "    '''\n",
    "    Cleans the data from special characters, urls, punctuation marks, extra spaces.\n",
    "    Removes stopwords (Like if, it, the etc) and transforms the word in its native\n",
    "    form using Porter Stemmer.\n",
    "    '''\n",
    "    text = str(text).lower() # lowercase the string\n",
    "    text = re.sub('\\[.*?\\]', ' ', text) # replace punctuation with whitespaces.\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text) # replacing urls with whitespaces.\n",
    "    text = re.sub('<.*?>+', ' ', text) # removes special characters\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text) # removes punctuation\n",
    "    text = re.sub('\\r', ' ', text) # removes new line characters\n",
    "    text = re.sub('\\n', ' ', text) # removes new line characters\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
    "    #text = re.sub('–', ' ', text) # remove any additional characters we cannot remove\n",
    "    text = re.sub('[–£…»]', ' ', text) # remove any additional characters we cannot remove\n",
    "    text = text.split()\n",
    "\n",
    "    # removing stopwords,\n",
    "    text = [word for word in text if not word in stopword ]\n",
    "\n",
    "    # stemming.\n",
    "    ps = PorterStemmer()\n",
    "    text = [ps.stem(word) for word in text]\n",
    "\n",
    "    if return_tokens:\n",
    "\n",
    "        # return relevant tokens here where needed\n",
    "        return text\n",
    "\n",
    "    #List to string.\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>664</td>\n",
       "      <td>2.690000e-08</td>\n",
       "      <td>1.860000e-08</td>\n",
       "      <td>4.050000e-06</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.210000e-10</td>\n",
       "      <td>8.230000e-12</td>\n",
       "      <td>9.020000e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.640000e-10</td>\n",
       "      <td>1.110000e-10</td>\n",
       "      <td>5.160000e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.170000e-09</td>\n",
       "      <td>6.330000e-10</td>\n",
       "      <td>1.560000e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>9349</td>\n",
       "      <td>3.790000e-07</td>\n",
       "      <td>3.830000e-07</td>\n",
       "      <td>3.460000e-05</td>\n",
       "      <td>1239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Seq_num  Word Count  Word Proportion  Average Proportion  \\\n",
       "0   AARDVARK        1         664     2.690000e-08        1.860000e-08   \n",
       "1  AARDVARKS        2           3     1.210000e-10        8.230000e-12   \n",
       "2      ABACI        3           9     3.640000e-10        1.110000e-10   \n",
       "3      ABACK        4          29     1.170000e-09        6.330000e-10   \n",
       "4     ABACUS        5        9349     3.790000e-07        3.830000e-07   \n",
       "\n",
       "        Std Dev  Doc Count  Negative  Positive  Uncertainty  Litigious  \\\n",
       "0  4.050000e-06        131         0         0            0          0   \n",
       "1  9.020000e-09          1         0         0            0          0   \n",
       "2  5.160000e-08          7         0         0            0          0   \n",
       "3  1.560000e-07         28         0         0            0          0   \n",
       "4  3.460000e-05       1239         0         0            0          0   \n",
       "\n",
       "   Strong_Modal  Weak_Modal  Constraining  Complexity  Syllables     Source  \n",
       "0             0           0             0           0          2  12of12inf  \n",
       "1             0           0             0           0          2  12of12inf  \n",
       "2             0           0             0           0          3  12of12inf  \n",
       "3             0           0             0           0          2  12of12inf  \n",
       "4             0           0             0           0          3  12of12inf  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_words_df = pd.read_csv(\"sentiment_dictionary/Loughran-McDonald_MasterDictionary_1993-2023.csv\")\n",
    "sentiment_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Word', 'Seq_num', 'Word Count', 'Word Proportion',\n",
       "       'Average Proportion', 'Std Dev', 'Doc Count', 'Negative', 'Positive',\n",
       "       'Uncertainty', 'Litigious', 'Strong_Modal', 'Weak_Modal',\n",
       "       'Constraining', 'Complexity', 'Syllables', 'Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract positive and negative words for workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125             abl\n",
       "336           abund\n",
       "338           abund\n",
       "438         acclaim\n",
       "477      accomplish\n",
       "            ...    \n",
       "85305           win\n",
       "85427        winner\n",
       "85428        winner\n",
       "85429           win\n",
       "85964        worthi\n",
       "Name: Word, Length: 347, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment_words_df[sentiment_words_df['Positive'] > 0]['Word'].apply(data_cleaner, return_tokens=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentiment word lists, convert it into data dictionary here\n",
    "positive_words = sentiment_words_df[sentiment_words_df['Positive'] > 0]['Word'].apply(data_cleaner, return_tokens=False)\n",
    "\n",
    "positive_words = set(positive_words)\n",
    "\n",
    "negative_words = sentiment_words_df[sentiment_words_df['Negative'] > 0]['Word'].apply(data_cleaner, return_tokens=False)\n",
    "\n",
    "negative_words = set(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125             [abl]\n",
       "336           [abund]\n",
       "338           [abund]\n",
       "438         [acclaim]\n",
       "477      [accomplish]\n",
       "             ...     \n",
       "85305           [win]\n",
       "85427        [winner]\n",
       "85428        [winner]\n",
       "85429           [win]\n",
       "85964        [worthi]\n",
       "Name: Word, Length: 347, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = re.sub(r'[^a-z\\s]', '', doc)\n",
    "    tokens = doc.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve, you can preprocess the tokens and code in the same way, and then use those words to preprocess the below.\n",
    "\n",
    "Use the same LDA preprocessing on both to get the sentiments as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(doc_tokens, positive_words, negative_words):\n",
    "    # tokens = preprocess_document(doc)\n",
    "    positive_count = sum(1 for word in doc_tokens if word in positive_words)\n",
    "    negative_count = sum(1 for word in doc_tokens if word in negative_words)\n",
    "    total_words = len(doc_tokens)\n",
    "    \n",
    "    sentiment_score = (positive_count - negative_count) / total_words if total_words else 0\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: The company had a great quarter with significant growth.\n",
      "Sentiment Score: 0.2\n",
      "\n",
      "Document: There were many challenges and losses in the last quarter.\n",
      "Sentiment Score: -0.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The company had a great quarter with significant growth.\",\n",
    "    \"There were many challenges and losses in the last quarter.\"\n",
    "]\n",
    "\n",
    "# Calculate and print sentiment scores\n",
    "for doc in documents:\n",
    "\n",
    "    preprocessed_doc = data_cleaner(doc, return_tokens=True)\n",
    "\n",
    "    score = calculate_sentiment(preprocessed_doc, positive_words, negative_words)\n",
    "    print(f'Document: {doc}\\nSentiment Score: {score}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing, and the code above, seems to make sense.\n",
    "\n",
    "So we can run this sentiment of words, but we can also try to use the other code workflows as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to count the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_report_df = pd.read_json(\"raw_data/sec_us_phrama_all_company_filing_meta_with_text_w_7_7A_2011_2023.jsonl\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'formType', 'accessionNo', 'cik', 'companyNameLong',\n",
       "       'companyName', 'linkToFilingDetails', 'description', 'linkToTxt',\n",
       "       'filedAt', 'documentFormatFiles', 'periodOfReport', 'entities', 'id',\n",
       "       'seriesAndClassesContractsInformation', 'linkToHtml', 'linkToXbrl',\n",
       "       'dataFiles', 'effectivenessDate', 'Text_7', 'Text_7A'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_report_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "section7_text_cleaned = annual_report_df[\"Text_7\"].parallel_apply(data_cleaner, return_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Item 7. MANAGEMENT&#8217;S DISCUSSION AND ANA...\n",
       "1        Item 7. MANAGEMENT&#8217;S DISCUSSION AND ANA...\n",
       "2        Item 7. MANAGEMENT&#8217;S DISCUSSION AND ANA...\n",
       "3        Item 7. MANAGEMENT&#8217;S DISCUSSION AND ANA...\n",
       "4                                                        \n",
       "                              ...                        \n",
       "8376     Item 7. Management&#8217;s Discussion and Ana...\n",
       "8377     Item 7. Management&#8217;s Discussion and Ana...\n",
       "8378     Item 7. Management&#8217;s Discussion and Ana...\n",
       "8379     Item 7. Management&#8217;s Discussion and Ana...\n",
       "8380     Item 7. Management&#8217;s Discussion and Ana...\n",
       "Name: Text_7, Length: 8381, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_report_df[\"Text_7\"]\n",
    "\n",
    "# it is right in the below, as you've got the same result so make sure you do this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_report_df[\"section7_cleaned\"] = section7_text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [item, manag, discuss, analysi, financi, condi...\n",
       "1       [item, manag, discuss, analysi, financi, condi...\n",
       "2       [item, manag, discuss, analysi, financi, condi...\n",
       "3       [item, manag, discuss, analysi, financi, condi...\n",
       "4                                                      []\n",
       "                              ...                        \n",
       "8376    [item, manag, discuss, analysi, financi, condi...\n",
       "8377    [item, manag, discuss, analysi, financi, condi...\n",
       "8378    [item, manag, discuss, analysi, financi, condi...\n",
       "8379    [item, manag, discuss, analysi, financi, condi...\n",
       "8380    [item, manag, discuss, analysi, financi, condi...\n",
       "Name: section7_cleaned, Length: 8381, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_report_df[\"section7_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_report_df[\"section7_cleaned_sentiment\"] = annual_report_df[\"section7_cleaned\"].parallel_apply(calculate_sentiment, positive_words = positive_words, negative_words = negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count positive values\n",
    "positive_count = (annual_report_df[\"section7_cleaned_sentiment\"] > 0).sum()\n",
    "\n",
    "# Count negative values\n",
    "negative_count = (annual_report_df[\"section7_cleaned_sentiment\"]  < 0).sum()\n",
    "\n",
    "# Count zero values\n",
    "zero_count = (annual_report_df[\"section7_cleaned_sentiment\"]  == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(956), np.int64(5496), np.int64(1929))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_count, negative_count, zero_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with uncertainty as required\n",
    "\n",
    "These are the words that G. used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the uncertainty words by the word list, same procedure as before.\n",
    "\n",
    "uncertainty_words =  sentiment_words_df[sentiment_words_df['Uncertainty'] > 0]['Word'].apply(data_cleaner, return_tokens=False)\n",
    "\n",
    "uncertainty_words = set(uncertainty_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uncertainty_words(words, uncertainty_words):\n",
    "    count = sum(1 for word in words if word in uncertainty_words)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uncertainty_score(text, uncertainty_words):\n",
    "    words = data_cleaner(text, return_tokens=True)\n",
    "    uncertainty_count = count_uncertainty_words(words, uncertainty_words)\n",
    "    # Normalize by the total number of words to get the score\n",
    "    score = uncertainty_count / len(words) if words else 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "text = \"I am very uncertain about the my future financial prospects\"\n",
    "uncertainty_score = calculate_uncertainty_score(text, uncertainty_words)\n",
    "print(f'Uncertainty Score: {uncertainty_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind of works - just use basic score words and this could work well.\n",
    "\n",
    "# expand and do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different measurements of scores for the procedure here that's it!!\n",
    "\n",
    "\n",
    "Try other drafts for the paper for submission later!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
